{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Financial Data Collection\n",
    "## Stock Prices, Returns, and Earnings Announcements\n",
    "\n",
    "---\n",
    "\n",
    "**Research Project:** Retail Sentiment, Earnings Quality, and Stock Returns\n",
    "\n",
    "**Purpose:** Collect financial market data and earnings announcement information for the stock universe.\n",
    "\n",
    "**Data Sources:**\n",
    "- Yahoo Finance (yfinance) - Daily stock prices\n",
    "- SEC EDGAR - Earnings announcements\n",
    "- Alternative APIs for analyst forecasts\n",
    "\n",
    "**Output:**\n",
    "- Daily stock returns panel\n",
    "- Earnings announcement events with surprise measures\n",
    "- Abnormal return calculations (CAR)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSTALL REQUIRED PACKAGES\n",
    "# =============================================================================\n",
    "\n",
    "!pip install yfinance==0.2.31\n",
    "!pip install pandas==2.0.3\n",
    "!pip install numpy==1.24.3\n",
    "!pip install pandas-datareader==0.10.0\n",
    "!pip install requests==2.31.0\n",
    "!pip install beautifulsoup4==4.12.2\n",
    "!pip install lxml==4.9.3\n",
    "!pip install pyarrow==14.0.1\n",
    "!pip install scipy==1.11.3\n",
    "!pip install statsmodels==0.14.0\n",
    "!pip install tqdm==4.66.1\n",
    "!pip install sec-edgar-downloader==5.0.0\n",
    "\n",
    "print(\"All packages installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Financial data\n",
    "import yfinance as yf\n",
    "import pandas_datareader as pdr\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(f\"Environment setup complete. Timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class FinancialDataConfig:\n",
    "    \"\"\"Configuration for financial data collection.\"\"\"\n",
    "    \n",
    "    # Data paths\n",
    "    BASE_PATH = \"/content/drive/MyDrive/Research/RetailSentiment/\"\n",
    "    RAW_DATA_PATH = BASE_PATH + \"data/raw/\"\n",
    "    PROCESSED_DATA_PATH = BASE_PATH + \"data/processed/\"\n",
    "    \n",
    "    # Sample period\n",
    "    START_DATE = \"2017-01-01\"  # Extra year for estimation window\n",
    "    END_DATE = \"2023-12-31\"\n",
    "    \n",
    "    # Event study parameters\n",
    "    ESTIMATION_WINDOW = 120  # Trading days for market model estimation\n",
    "    ESTIMATION_GAP = 10  # Gap between estimation and event window\n",
    "    \n",
    "    # Market indices\n",
    "    MARKET_INDEX = \"SPY\"  # S&P 500 ETF as market proxy\n",
    "    RISK_FREE_PROXY = \"^IRX\"  # 13-week T-Bill rate\n",
    "    \n",
    "    # Fama-French factors\n",
    "    USE_FF_FACTORS = True\n",
    "    FF_FACTORS = ['Mkt-RF', 'SMB', 'HML', 'RF']  # 3-factor model\n",
    "    \n",
    "    # API limits\n",
    "    YAHOO_RATE_LIMIT = 2000  # Requests per hour\n",
    "    BATCH_SIZE = 50  # Tickers per batch\n",
    "    SLEEP_BETWEEN_BATCHES = 1.0\n",
    "    \n",
    "    @classmethod\n",
    "    def print_config(cls):\n",
    "        print(\"=\"*60)\n",
    "        print(\"FINANCIAL DATA CONFIGURATION\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Period: {cls.START_DATE} to {cls.END_DATE}\")\n",
    "        print(f\"Market Index: {cls.MARKET_INDEX}\")\n",
    "        print(f\"Estimation Window: {cls.ESTIMATION_WINDOW} days\")\n",
    "        print(f\"Use Fama-French: {cls.USE_FF_FACTORS}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "config = FinancialDataConfig()\n",
    "config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MOUNT GOOGLE DRIVE\n",
    "# =============================================================================\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.makedirs(config.RAW_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(config.PROCESSED_DATA_PATH, exist_ok=True)\n",
    "print(\"Data directories ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Ticker Universe\n",
    "\n",
    "Load the ticker universe from the social media data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD TICKER UNIVERSE\n",
    "# =============================================================================\n",
    "\n",
    "def load_ticker_universe(data_path: str) -> List[str]:\n",
    "    \"\"\"Load ticker universe from firm-day panel.\n",
    "    \n",
    "    Args:\n",
    "        data_path: Path to processed data\n",
    "        \n",
    "    Returns:\n",
    "        List of unique tickers\n",
    "    \"\"\"\n",
    "    # Load firm-day panel\n",
    "    filepath = os.path.join(data_path, 'wsb_firm_day_panel.parquet')\n",
    "    \n",
    "    if os.path.exists(filepath):\n",
    "        df = pd.read_parquet(filepath)\n",
    "        tickers = df['ticker'].unique().tolist()\n",
    "        print(f\"Loaded {len(tickers)} tickers from firm-day panel\")\n",
    "    else:\n",
    "        # Fallback: Load S&P 500\n",
    "        print(\"Firm-day panel not found. Loading S&P 500 tickers...\")\n",
    "        tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "        sp500 = tables[0]\n",
    "        tickers = sp500['Symbol'].str.replace('.', '-').tolist()\n",
    "        print(f\"Loaded {len(tickers)} S&P 500 tickers\")\n",
    "    \n",
    "    return sorted(tickers)\n",
    "\n",
    "# Load tickers\n",
    "tickers = load_ticker_universe(config.PROCESSED_DATA_PATH)\n",
    "print(f\"\\nSample tickers: {tickers[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stock Price Data Collection\n",
    "\n",
    "### 3.1 Yahoo Finance Price Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YAHOO FINANCE DATA COLLECTOR\n",
    "# =============================================================================\n",
    "\n",
    "class YahooFinanceCollector:\n",
    "    \"\"\"Collects stock price data from Yahoo Finance.\n",
    "    \n",
    "    Features:\n",
    "    - Batch downloading for efficiency\n",
    "    - Automatic retry on failures\n",
    "    - Adjusted close prices for splits/dividends\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: FinancialDataConfig):\n",
    "        self.config = config\n",
    "        self.failed_tickers = []\n",
    "        \n",
    "    def download_prices(\n",
    "        self,\n",
    "        tickers: List[str],\n",
    "        start_date: str,\n",
    "        end_date: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Download daily price data for multiple tickers.\n",
    "        \n",
    "        Args:\n",
    "            tickers: List of ticker symbols\n",
    "            start_date: Start date (YYYY-MM-DD)\n",
    "            end_date: End date (YYYY-MM-DD)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with daily OHLCV data\n",
    "        \"\"\"\n",
    "        print(f\"Downloading prices for {len(tickers)} tickers...\")\n",
    "        print(f\"Period: {start_date} to {end_date}\")\n",
    "        \n",
    "        all_data = []\n",
    "        self.failed_tickers = []\n",
    "        \n",
    "        # Process in batches\n",
    "        batches = [tickers[i:i+self.config.BATCH_SIZE] \n",
    "                   for i in range(0, len(tickers), self.config.BATCH_SIZE)]\n",
    "        \n",
    "        for batch in tqdm(batches, desc=\"Downloading batches\"):\n",
    "            try:\n",
    "                # Download batch\n",
    "                data = yf.download(\n",
    "                    batch,\n",
    "                    start=start_date,\n",
    "                    end=end_date,\n",
    "                    auto_adjust=True,  # Adjust for splits/dividends\n",
    "                    progress=False,\n",
    "                    threads=True\n",
    "                )\n",
    "                \n",
    "                if len(batch) == 1:\n",
    "                    # Single ticker returns different format\n",
    "                    data.columns = pd.MultiIndex.from_product(\n",
    "                        [data.columns, batch]\n",
    "                    )\n",
    "                \n",
    "                # Reshape to long format\n",
    "                for ticker in batch:\n",
    "                    if ticker in data.columns.get_level_values(1):\n",
    "                        ticker_data = data.xs(ticker, level=1, axis=1).copy()\n",
    "                        ticker_data['ticker'] = ticker\n",
    "                        ticker_data = ticker_data.reset_index()\n",
    "                        ticker_data.columns = ['date', 'open', 'high', 'low', \n",
    "                                               'close', 'volume', 'ticker']\n",
    "                        all_data.append(ticker_data)\n",
    "                    else:\n",
    "                        self.failed_tickers.append(ticker)\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading batch: {e}\")\n",
    "                self.failed_tickers.extend(batch)\n",
    "            \n",
    "            # Rate limiting\n",
    "            time.sleep(self.config.SLEEP_BETWEEN_BATCHES)\n",
    "        \n",
    "        # Combine all data\n",
    "        if all_data:\n",
    "            df = pd.concat(all_data, ignore_index=True)\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            print(f\"\\nDownload complete:\")\n",
    "            print(f\"  Total observations: {len(df):,}\")\n",
    "            print(f\"  Tickers downloaded: {df['ticker'].nunique()}\")\n",
    "            print(f\"  Failed tickers: {len(self.failed_tickers)}\")\n",
    "            \n",
    "            return df\n",
    "        else:\n",
    "            print(\"No data downloaded!\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def download_market_data(\n",
    "        self,\n",
    "        start_date: str,\n",
    "        end_date: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Download market index data.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame with market returns\n",
    "        \"\"\"\n",
    "        print(f\"Downloading market data ({self.config.MARKET_INDEX})...\")\n",
    "        \n",
    "        market = yf.download(\n",
    "            self.config.MARKET_INDEX,\n",
    "            start=start_date,\n",
    "            end=end_date,\n",
    "            auto_adjust=True,\n",
    "            progress=False\n",
    "        )\n",
    "        \n",
    "        market = market.reset_index()\n",
    "        market.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n",
    "        market['market_return'] = market['close'].pct_change()\n",
    "        \n",
    "        print(f\"Market data: {len(market)} observations\")\n",
    "        return market[['date', 'close', 'market_return']].rename(\n",
    "            columns={'close': 'market_price'}\n",
    "        )\n",
    "\n",
    "# Initialize collector\n",
    "price_collector = YahooFinanceCollector(config)\n",
    "print(\"Yahoo Finance collector initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOWNLOAD PRICE DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Download stock prices\n",
    "stock_prices = price_collector.download_prices(\n",
    "    tickers,\n",
    "    config.START_DATE,\n",
    "    config.END_DATE\n",
    ")\n",
    "\n",
    "# Download market data\n",
    "market_data = price_collector.download_market_data(\n",
    "    config.START_DATE,\n",
    "    config.END_DATE\n",
    ")\n",
    "\n",
    "# Save checkpoint\n",
    "stock_prices.to_parquet(\n",
    "    os.path.join(config.RAW_DATA_PATH, 'stock_prices_raw.parquet'),\n",
    "    index=False\n",
    ")\n",
    "print(\"Price data saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Calculate Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RETURN CALCULATIONS\n",
    "# =============================================================================\n",
    "\n",
    "class ReturnCalculator:\n",
    "    \"\"\"Calculates various return measures.\n",
    "    \n",
    "    Following standard event study methodology:\n",
    "    - Simple returns\n",
    "    - Log returns\n",
    "    - Market-adjusted returns\n",
    "    - Risk-adjusted returns (market model)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def calculate_returns(self, prices: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate daily returns from price data.\n",
    "        \n",
    "        Args:\n",
    "            prices: DataFrame with columns [date, ticker, close]\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with return columns added\n",
    "        \"\"\"\n",
    "        print(\"Calculating returns...\")\n",
    "        df = prices.sort_values(['ticker', 'date']).copy()\n",
    "        \n",
    "        # Simple return\n",
    "        df['ret'] = df.groupby('ticker')['close'].pct_change()\n",
    "        \n",
    "        # Log return\n",
    "        df['ret_log'] = np.log(df['close'] / df.groupby('ticker')['close'].shift(1))\n",
    "        \n",
    "        # Lagged prices for return calculations\n",
    "        df['price_lag1'] = df.groupby('ticker')['close'].shift(1)\n",
    "        df['price_lag2'] = df.groupby('ticker')['close'].shift(2)\n",
    "        \n",
    "        # Trading volume in dollars\n",
    "        df['dollar_volume'] = df['close'] * df['volume']\n",
    "        \n",
    "        # Volatility (rolling 20-day)\n",
    "        df['volatility_20d'] = df.groupby('ticker')['ret'].transform(\n",
    "            lambda x: x.rolling(window=20, min_periods=10).std() * np.sqrt(252)\n",
    "        )\n",
    "        \n",
    "        print(f\"Returns calculated for {df['ticker'].nunique()} tickers\")\n",
    "        return df\n",
    "    \n",
    "    def merge_market_returns(self, stock_returns: pd.DataFrame,\n",
    "                             market_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Merge market returns with stock returns.\n",
    "        \n",
    "        Args:\n",
    "            stock_returns: Stock return DataFrame\n",
    "            market_data: Market index DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            Merged DataFrame\n",
    "        \"\"\"\n",
    "        print(\"Merging with market data...\")\n",
    "        \n",
    "        df = stock_returns.merge(\n",
    "            market_data[['date', 'market_return']],\n",
    "            on='date',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Market-adjusted return\n",
    "        df['ret_mktadj'] = df['ret'] - df['market_return']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def estimate_market_model(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        estimation_window: int = 120,\n",
    "        min_observations: int = 60\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Estimate market model parameters for each ticker.\n",
    "        \n",
    "        Model: R_it = alpha_i + beta_i * R_mt + epsilon_it\n",
    "        \n",
    "        Args:\n",
    "            df: Stock returns DataFrame with market returns\n",
    "            estimation_window: Days for estimation\n",
    "            min_observations: Minimum required observations\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with model parameters\n",
    "        \"\"\"\n",
    "        print(f\"Estimating market model (window={estimation_window} days)...\")\n",
    "        \n",
    "        params_list = []\n",
    "        \n",
    "        for ticker in tqdm(df['ticker'].unique(), desc=\"Estimating\"):\n",
    "            ticker_data = df[df['ticker'] == ticker].sort_values('date')\n",
    "            \n",
    "            if len(ticker_data) < min_observations:\n",
    "                continue\n",
    "            \n",
    "            # Use rolling estimation\n",
    "            for i in range(estimation_window, len(ticker_data)):\n",
    "                window_data = ticker_data.iloc[i-estimation_window:i]\n",
    "                \n",
    "                # Clean data\n",
    "                clean_data = window_data[['ret', 'market_return']].dropna()\n",
    "                \n",
    "                if len(clean_data) < min_observations:\n",
    "                    continue\n",
    "                \n",
    "                # Estimate market model\n",
    "                X = sm.add_constant(clean_data['market_return'])\n",
    "                y = clean_data['ret']\n",
    "                \n",
    "                try:\n",
    "                    model = sm.OLS(y, X).fit()\n",
    "                    \n",
    "                    params_list.append({\n",
    "                        'ticker': ticker,\n",
    "                        'date': ticker_data.iloc[i]['date'],\n",
    "                        'alpha': model.params[0],\n",
    "                        'beta': model.params[1],\n",
    "                        'r_squared': model.rsquared,\n",
    "                        'residual_std': model.resid.std()\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        params_df = pd.DataFrame(params_list)\n",
    "        print(f\"Model parameters estimated for {params_df['ticker'].nunique()} tickers\")\n",
    "        \n",
    "        return params_df\n",
    "\n",
    "# Initialize calculator\n",
    "return_calc = ReturnCalculator()\n",
    "\n",
    "# Calculate returns\n",
    "stock_returns = return_calc.calculate_returns(stock_prices)\n",
    "stock_returns = return_calc.merge_market_returns(stock_returns, market_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ESTIMATE MARKET MODEL (Optional - computationally intensive)\n",
    "# =============================================================================\n",
    "\n",
    "# Note: This is computationally intensive. Run if needed for CAR calculations.\n",
    "# For large samples, consider estimating only around event windows.\n",
    "\n",
    "ESTIMATE_MARKET_MODEL = False  # Set to True if needed\n",
    "\n",
    "if ESTIMATE_MARKET_MODEL:\n",
    "    market_model_params = return_calc.estimate_market_model(\n",
    "        stock_returns,\n",
    "        estimation_window=config.ESTIMATION_WINDOW,\n",
    "        min_observations=60\n",
    "    )\n",
    "    \n",
    "    # Save parameters\n",
    "    market_model_params.to_parquet(\n",
    "        os.path.join(config.PROCESSED_DATA_PATH, 'market_model_params.parquet'),\n",
    "        index=False\n",
    "    )\n",
    "else:\n",
    "    print(\"Skipping market model estimation (set ESTIMATE_MARKET_MODEL=True to run)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Download Fama-French Factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FAMA-FRENCH FACTORS\n",
    "# =============================================================================\n",
    "\n",
    "class FamaFrenchLoader:\n",
    "    \"\"\"Loads Fama-French factor data from Ken French's data library.\"\"\"\n",
    "    \n",
    "    FF_URL = \"https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/ftp/\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_factors(self, start_date: str, end_date: str,\n",
    "                    model: str = '3factor') -> pd.DataFrame:\n",
    "        \"\"\"Load Fama-French factors.\n",
    "        \n",
    "        Args:\n",
    "            start_date: Start date\n",
    "            end_date: End date\n",
    "            model: '3factor' or '5factor'\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with daily factor returns\n",
    "        \"\"\"\n",
    "        print(f\"Loading Fama-French {model} factors...\")\n",
    "        \n",
    "        try:\n",
    "            # Use pandas_datareader to fetch FF factors\n",
    "            if model == '3factor':\n",
    "                ff = pdr.get_data_famafrench(\n",
    "                    'F-F_Research_Data_Factors_daily',\n",
    "                    start=start_date,\n",
    "                    end=end_date\n",
    "                )[0]\n",
    "            else:\n",
    "                ff = pdr.get_data_famafrench(\n",
    "                    'F-F_Research_Data_5_Factors_2x3_daily',\n",
    "                    start=start_date,\n",
    "                    end=end_date\n",
    "                )[0]\n",
    "            \n",
    "            # Convert to proper format\n",
    "            ff = ff.reset_index()\n",
    "            ff.columns = ff.columns.str.strip()\n",
    "            ff = ff.rename(columns={'Date': 'date'})\n",
    "            \n",
    "            # Convert percentages to decimals\n",
    "            for col in ff.columns:\n",
    "                if col != 'date':\n",
    "                    ff[col] = ff[col] / 100\n",
    "            \n",
    "            ff['date'] = pd.to_datetime(ff['date'])\n",
    "            \n",
    "            print(f\"Loaded {len(ff)} observations\")\n",
    "            print(f\"Columns: {list(ff.columns)}\")\n",
    "            \n",
    "            return ff\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading FF factors: {e}\")\n",
    "            print(\"Attempting alternative method...\")\n",
    "            return self._load_from_url(start_date, end_date, model)\n",
    "    \n",
    "    def _load_from_url(self, start_date: str, end_date: str,\n",
    "                      model: str) -> pd.DataFrame:\n",
    "        \"\"\"Fallback method to load from URL directly.\"\"\"\n",
    "        # This is a fallback - implement if pandas_datareader fails\n",
    "        print(\"URL fallback not implemented - returning empty DataFrame\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load Fama-French factors\n",
    "ff_loader = FamaFrenchLoader()\n",
    "ff_factors = ff_loader.load_factors(\n",
    "    config.START_DATE,\n",
    "    config.END_DATE,\n",
    "    model='3factor'\n",
    ")\n",
    "\n",
    "# Merge with stock returns\n",
    "if len(ff_factors) > 0:\n",
    "    stock_returns = stock_returns.merge(\n",
    "        ff_factors,\n",
    "        on='date',\n",
    "        how='left'\n",
    "    )\n",
    "    print(\"Fama-French factors merged.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Earnings Announcement Data\n",
    "\n",
    "### 4.1 Collect Earnings Dates and Actual EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EARNINGS DATA COLLECTOR\n",
    "# =============================================================================\n",
    "\n",
    "class EarningsDataCollector:\n",
    "    \"\"\"Collects earnings announcement data from multiple sources.\n",
    "    \n",
    "    Sources:\n",
    "    - Yahoo Finance earnings calendar\n",
    "    - SEC EDGAR filings\n",
    "    - Alternative APIs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.earnings_data = []\n",
    "        \n",
    "    def get_earnings_yahoo(self, tickers: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Get earnings data from Yahoo Finance.\n",
    "        \n",
    "        Args:\n",
    "            tickers: List of ticker symbols\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with earnings announcements\n",
    "        \"\"\"\n",
    "        print(f\"Collecting earnings data for {len(tickers)} tickers...\")\n",
    "        earnings_list = []\n",
    "        \n",
    "        for ticker in tqdm(tickers, desc=\"Fetching earnings\"):\n",
    "            try:\n",
    "                stock = yf.Ticker(ticker)\n",
    "                \n",
    "                # Get earnings dates\n",
    "                earnings = stock.earnings_dates\n",
    "                \n",
    "                if earnings is not None and len(earnings) > 0:\n",
    "                    earnings_df = earnings.reset_index()\n",
    "                    earnings_df['ticker'] = ticker\n",
    "                    earnings_list.append(earnings_df)\n",
    "                \n",
    "                # Get quarterly earnings history\n",
    "                quarterly = stock.quarterly_earnings\n",
    "                if quarterly is not None and len(quarterly) > 0:\n",
    "                    # This contains actual EPS\n",
    "                    pass\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "            \n",
    "            time.sleep(0.1)  # Rate limiting\n",
    "        \n",
    "        if earnings_list:\n",
    "            df = pd.concat(earnings_list, ignore_index=True)\n",
    "            print(f\"Collected earnings for {df['ticker'].nunique()} tickers\")\n",
    "            return df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def get_earnings_history(self, tickers: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Get historical earnings (actual and estimated EPS).\n",
    "        \n",
    "        Args:\n",
    "            tickers: List of ticker symbols\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with historical earnings\n",
    "        \"\"\"\n",
    "        print(f\"Collecting earnings history...\")\n",
    "        earnings_list = []\n",
    "        \n",
    "        for ticker in tqdm(tickers, desc=\"Fetching earnings history\"):\n",
    "            try:\n",
    "                stock = yf.Ticker(ticker)\n",
    "                \n",
    "                # Quarterly financials\n",
    "                quarterly = stock.quarterly_financials\n",
    "                if quarterly is not None and not quarterly.empty:\n",
    "                    # Get relevant rows\n",
    "                    if 'Net Income' in quarterly.index:\n",
    "                        net_income = quarterly.loc['Net Income']\n",
    "                        \n",
    "                        # Get shares outstanding for EPS calculation\n",
    "                        info = stock.info\n",
    "                        shares = info.get('sharesOutstanding', None)\n",
    "                        \n",
    "                        for date, ni in net_income.items():\n",
    "                            earnings_list.append({\n",
    "                                'ticker': ticker,\n",
    "                                'period_end': date,\n",
    "                                'net_income': ni,\n",
    "                                'shares_outstanding': shares,\n",
    "                                'eps_calculated': ni / shares if shares else None\n",
    "                            })\n",
    "                            \n",
    "            except Exception as e:\n",
    "                continue\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        if earnings_list:\n",
    "            df = pd.DataFrame(earnings_list)\n",
    "            df['period_end'] = pd.to_datetime(df['period_end'])\n",
    "            return df\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# Initialize collector\n",
    "earnings_collector = EarningsDataCollector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COLLECT EARNINGS DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Collect earnings dates\n",
    "earnings_dates = earnings_collector.get_earnings_yahoo(tickers[:100])  # Subset for demo\n",
    "\n",
    "if len(earnings_dates) > 0:\n",
    "    print(f\"\\nEarnings data collected:\")\n",
    "    print(earnings_dates.head())\n",
    "    \n",
    "    # Save\n",
    "    earnings_dates.to_parquet(\n",
    "        os.path.join(config.RAW_DATA_PATH, 'earnings_dates_raw.parquet'),\n",
    "        index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Calculate Earnings Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EARNINGS SURPRISE CALCULATION\n",
    "# =============================================================================\n",
    "\n",
    "class EarningsSurpriseCalculator:\n",
    "    \"\"\"Calculates earnings surprise measures.\n",
    "    \n",
    "    Methods:\n",
    "    1. Analyst forecast-based: (Actual - Consensus) / Price\n",
    "    2. Seasonal random walk: (EPS_t - EPS_{t-4}) / Price\n",
    "    3. Time-series model: AR(1) residuals\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def seasonal_random_walk_surprise(\n",
    "        self,\n",
    "        earnings: pd.DataFrame,\n",
    "        prices: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Calculate earnings surprise using seasonal random walk.\n",
    "        \n",
    "        SUE = (EPS_q - EPS_{q-4}) / Price_{t-2}\n",
    "        \n",
    "        This is a common proxy when analyst forecasts are unavailable.\n",
    "        \n",
    "        Args:\n",
    "            earnings: DataFrame with [ticker, period_end, eps]\n",
    "            prices: DataFrame with [ticker, date, close]\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with surprise measures\n",
    "        \"\"\"\n",
    "        print(\"Calculating seasonal random walk surprise...\")\n",
    "        \n",
    "        # Sort and compute lagged EPS\n",
    "        df = earnings.sort_values(['ticker', 'period_end']).copy()\n",
    "        df['eps_lag4'] = df.groupby('ticker')['eps_calculated'].shift(4)\n",
    "        \n",
    "        # EPS change\n",
    "        df['eps_change'] = df['eps_calculated'] - df['eps_lag4']\n",
    "        \n",
    "        # Merge with price data (price 2 days before announcement)\n",
    "        # This requires EA date mapping - simplified here\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def standardized_unexpected_earnings(\n",
    "        self,\n",
    "        earnings: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Calculate Standardized Unexpected Earnings (SUE).\n",
    "        \n",
    "        SUE = (EPS_t - E[EPS_t]) / σ(EPS)\n",
    "        \n",
    "        Where expectation is based on seasonal random walk.\n",
    "        \"\"\"\n",
    "        df = earnings.sort_values(['ticker', 'period_end']).copy()\n",
    "        \n",
    "        # Expected EPS (same quarter last year)\n",
    "        df['eps_expected'] = df.groupby('ticker')['eps_calculated'].shift(4)\n",
    "        \n",
    "        # Forecast error\n",
    "        df['forecast_error'] = df['eps_calculated'] - df['eps_expected']\n",
    "        \n",
    "        # Rolling standard deviation of forecast errors\n",
    "        df['forecast_error_std'] = df.groupby('ticker')['forecast_error'].transform(\n",
    "            lambda x: x.rolling(window=8, min_periods=4).std()\n",
    "        )\n",
    "        \n",
    "        # SUE\n",
    "        df['SUE'] = df['forecast_error'] / df['forecast_error_std']\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Initialize calculator\n",
    "surprise_calc = EarningsSurpriseCalculator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cumulative Abnormal Returns (CAR)\n",
    "\n",
    "### 5.1 Event Study Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CUMULATIVE ABNORMAL RETURN CALCULATOR\n",
    "# =============================================================================\n",
    "\n",
    "class CARCalculator:\n",
    "    \"\"\"Calculates Cumulative Abnormal Returns for event studies.\n",
    "    \n",
    "    Supports multiple methodologies:\n",
    "    1. Market-adjusted returns: AR = R - R_m\n",
    "    2. Market model: AR = R - (alpha + beta * R_m)\n",
    "    3. Fama-French 3-factor model\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, stock_returns: pd.DataFrame):\n",
    "        \"\"\"Initialize with stock returns data.\n",
    "        \n",
    "        Args:\n",
    "            stock_returns: DataFrame with daily returns\n",
    "        \"\"\"\n",
    "        self.returns = stock_returns.copy()\n",
    "        self.returns['date'] = pd.to_datetime(self.returns['date'])\n",
    "        \n",
    "    def get_trading_days_around_event(\n",
    "        self,\n",
    "        ticker: str,\n",
    "        event_date: datetime,\n",
    "        window_start: int,\n",
    "        window_end: int\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Get trading days around an event date.\n",
    "        \n",
    "        Args:\n",
    "            ticker: Stock ticker\n",
    "            event_date: Event date\n",
    "            window_start: Start of window (negative = before)\n",
    "            window_end: End of window\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with trading days in window\n",
    "        \"\"\"\n",
    "        ticker_data = self.returns[self.returns['ticker'] == ticker].copy()\n",
    "        ticker_data = ticker_data.sort_values('date')\n",
    "        \n",
    "        # Find event date index\n",
    "        dates = ticker_data['date'].values\n",
    "        event_idx = np.searchsorted(dates, np.datetime64(event_date))\n",
    "        \n",
    "        # Get window indices\n",
    "        start_idx = max(0, event_idx + window_start)\n",
    "        end_idx = min(len(ticker_data), event_idx + window_end + 1)\n",
    "        \n",
    "        return ticker_data.iloc[start_idx:end_idx].copy()\n",
    "    \n",
    "    def calculate_car_market_adjusted(\n",
    "        self,\n",
    "        ticker: str,\n",
    "        event_date: datetime,\n",
    "        window_start: int = -1,\n",
    "        window_end: int = 1\n",
    "    ) -> Dict:\n",
    "        \"\"\"Calculate market-adjusted CAR.\n",
    "        \n",
    "        CAR = Σ (R_it - R_mt) for t in [window_start, window_end]\n",
    "        \n",
    "        Args:\n",
    "            ticker: Stock ticker\n",
    "            event_date: Event date\n",
    "            window_start: Start of event window\n",
    "            window_end: End of event window\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with CAR and related statistics\n",
    "        \"\"\"\n",
    "        window_data = self.get_trading_days_around_event(\n",
    "            ticker, event_date, window_start, window_end\n",
    "        )\n",
    "        \n",
    "        if len(window_data) == 0:\n",
    "            return {\n",
    "                'ticker': ticker,\n",
    "                'event_date': event_date,\n",
    "                'car': np.nan,\n",
    "                'window': f'[{window_start},{window_end}]',\n",
    "                'n_days': 0\n",
    "            }\n",
    "        \n",
    "        # Calculate abnormal returns\n",
    "        window_data['ar'] = window_data['ret'] - window_data['market_return']\n",
    "        \n",
    "        # Cumulative abnormal return\n",
    "        car = window_data['ar'].sum()\n",
    "        \n",
    "        return {\n",
    "            'ticker': ticker,\n",
    "            'event_date': event_date,\n",
    "            'car': car,\n",
    "            'window': f'[{window_start},{window_end}]',\n",
    "            'n_days': len(window_data),\n",
    "            'avg_ar': window_data['ar'].mean(),\n",
    "            'raw_return': window_data['ret'].sum()\n",
    "        }\n",
    "    \n",
    "    def calculate_cars_for_events(\n",
    "        self,\n",
    "        events: pd.DataFrame,\n",
    "        windows: List[Tuple[int, int]] = [(-1, 1), (0, 2), (2, 20)]\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Calculate CARs for multiple events and windows.\n",
    "        \n",
    "        Args:\n",
    "            events: DataFrame with [ticker, event_date]\n",
    "            windows: List of (start, end) tuples\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with CARs for each event-window combination\n",
    "        \"\"\"\n",
    "        print(f\"Calculating CARs for {len(events)} events...\")\n",
    "        print(f\"Windows: {windows}\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for _, event in tqdm(events.iterrows(), total=len(events), desc=\"Processing events\"):\n",
    "            ticker = event['ticker']\n",
    "            event_date = pd.to_datetime(event['event_date'])\n",
    "            \n",
    "            event_results = {'ticker': ticker, 'event_date': event_date}\n",
    "            \n",
    "            for window_start, window_end in windows:\n",
    "                car_result = self.calculate_car_market_adjusted(\n",
    "                    ticker, event_date, window_start, window_end\n",
    "                )\n",
    "                window_name = f'CAR_{window_start}_{window_end}'\n",
    "                event_results[window_name] = car_result['car']\n",
    "            \n",
    "            results.append(event_results)\n",
    "        \n",
    "        df = pd.DataFrame(results)\n",
    "        print(f\"CAR calculations complete: {len(df)} events\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Initialize CAR calculator\n",
    "car_calculator = CARCalculator(stock_returns)\n",
    "print(\"CAR calculator initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXAMPLE: CALCULATE CARS FOR SAMPLE EVENTS\n",
    "# =============================================================================\n",
    "\n",
    "# Create sample events (replace with actual earnings dates)\n",
    "sample_events = pd.DataFrame({\n",
    "    'ticker': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META'],\n",
    "    'event_date': ['2023-01-26', '2023-01-24', '2023-02-02', \n",
    "                   '2023-02-02', '2023-02-01']\n",
    "})\n",
    "sample_events['event_date'] = pd.to_datetime(sample_events['event_date'])\n",
    "\n",
    "# Define event windows\n",
    "event_windows = [\n",
    "    (-1, 1),   # EA window: CAR[-1,+1]\n",
    "    (0, 2),    # Post-EA: CAR[0,+2]\n",
    "    (2, 20),   # Drift: CAR[+2,+20]\n",
    "    (-10, -2)  # Pre-EA: CAR[-10,-2]\n",
    "]\n",
    "\n",
    "# Calculate CARs\n",
    "sample_cars = car_calculator.calculate_cars_for_events(\n",
    "    sample_events,\n",
    "    windows=event_windows\n",
    ")\n",
    "\n",
    "print(\"\\nSample CAR Results:\")\n",
    "print(sample_cars.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Firm Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FIRM CHARACTERISTICS\n",
    "# =============================================================================\n",
    "\n",
    "class FirmCharacteristicsCollector:\n",
    "    \"\"\"Collects firm-level characteristics for control variables.\n",
    "    \n",
    "    Variables:\n",
    "    - Market capitalization (size)\n",
    "    - Book-to-market ratio\n",
    "    - Prior returns (momentum)\n",
    "    - Volatility\n",
    "    - Industry/sector\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_firm_info(self, tickers: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Get firm characteristics from Yahoo Finance.\n",
    "        \n",
    "        Args:\n",
    "            tickers: List of ticker symbols\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with firm characteristics\n",
    "        \"\"\"\n",
    "        print(f\"Collecting firm characteristics for {len(tickers)} tickers...\")\n",
    "        \n",
    "        firm_data = []\n",
    "        \n",
    "        for ticker in tqdm(tickers, desc=\"Fetching firm info\"):\n",
    "            try:\n",
    "                stock = yf.Ticker(ticker)\n",
    "                info = stock.info\n",
    "                \n",
    "                firm_data.append({\n",
    "                    'ticker': ticker,\n",
    "                    'company_name': info.get('longName', ''),\n",
    "                    'sector': info.get('sector', ''),\n",
    "                    'industry': info.get('industry', ''),\n",
    "                    'market_cap': info.get('marketCap', np.nan),\n",
    "                    'enterprise_value': info.get('enterpriseValue', np.nan),\n",
    "                    'book_value': info.get('bookValue', np.nan),\n",
    "                    'price_to_book': info.get('priceToBook', np.nan),\n",
    "                    'trailing_pe': info.get('trailingPE', np.nan),\n",
    "                    'forward_pe': info.get('forwardPE', np.nan),\n",
    "                    'beta': info.get('beta', np.nan),\n",
    "                    'avg_volume': info.get('averageVolume', np.nan),\n",
    "                    'shares_outstanding': info.get('sharesOutstanding', np.nan),\n",
    "                    'float_shares': info.get('floatShares', np.nan),\n",
    "                    'short_ratio': info.get('shortRatio', np.nan)\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                firm_data.append({'ticker': ticker})\n",
    "            \n",
    "            time.sleep(0.1)\n",
    "        \n",
    "        df = pd.DataFrame(firm_data)\n",
    "        print(f\"Collected info for {len(df)} firms\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_time_varying_characteristics(\n",
    "        self,\n",
    "        returns: pd.DataFrame\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Calculate time-varying characteristics.\n",
    "        \n",
    "        Args:\n",
    "            returns: Stock returns DataFrame\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with rolling characteristics\n",
    "        \"\"\"\n",
    "        print(\"Calculating time-varying characteristics...\")\n",
    "        df = returns.sort_values(['ticker', 'date']).copy()\n",
    "        \n",
    "        # Prior returns (momentum)\n",
    "        df['ret_1m'] = df.groupby('ticker')['ret'].transform(\n",
    "            lambda x: x.rolling(21).sum()\n",
    "        )\n",
    "        df['ret_3m'] = df.groupby('ticker')['ret'].transform(\n",
    "            lambda x: x.rolling(63).sum()\n",
    "        )\n",
    "        df['ret_6m'] = df.groupby('ticker')['ret'].transform(\n",
    "            lambda x: x.rolling(126).sum()\n",
    "        )\n",
    "        df['ret_12m'] = df.groupby('ticker')['ret'].transform(\n",
    "            lambda x: x.rolling(252).sum()\n",
    "        )\n",
    "        \n",
    "        # Volatility (annualized)\n",
    "        df['vol_1m'] = df.groupby('ticker')['ret'].transform(\n",
    "            lambda x: x.rolling(21).std() * np.sqrt(252)\n",
    "        )\n",
    "        df['vol_3m'] = df.groupby('ticker')['ret'].transform(\n",
    "            lambda x: x.rolling(63).std() * np.sqrt(252)\n",
    "        )\n",
    "        \n",
    "        # Illiquidity (Amihud)\n",
    "        df['illiquidity'] = np.abs(df['ret']) / (df['dollar_volume'] / 1e6)\n",
    "        df['illiquidity_avg'] = df.groupby('ticker')['illiquidity'].transform(\n",
    "            lambda x: x.rolling(21).mean()\n",
    "        )\n",
    "        \n",
    "        # Market cap (daily)\n",
    "        df['log_mcap'] = np.log(df['close'] * df.groupby('ticker')['volume'].transform('mean') * 1e6)\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Initialize collector\n",
    "char_collector = FirmCharacteristicsCollector()\n",
    "\n",
    "# Collect firm info (subset for demo)\n",
    "firm_characteristics = char_collector.get_firm_info(tickers[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ADD TIME-VARYING CHARACTERISTICS TO RETURNS\n",
    "# =============================================================================\n",
    "\n",
    "# Calculate time-varying characteristics\n",
    "stock_returns = char_collector.calculate_time_varying_characteristics(stock_returns)\n",
    "\n",
    "print(\"Time-varying characteristics added.\")\n",
    "print(f\"Columns: {list(stock_returns.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE ALL OUTPUTS\n",
    "# =============================================================================\n",
    "\n",
    "def save_financial_data(output_dir: str):\n",
    "    \"\"\"Save all financial data with documentation.\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Stock returns panel\n",
    "    stock_returns.to_parquet(\n",
    "        os.path.join(output_dir, 'stock_returns_panel.parquet'),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"Saved: stock_returns_panel.parquet ({len(stock_returns):,} rows)\")\n",
    "    \n",
    "    # Market data\n",
    "    market_data.to_parquet(\n",
    "        os.path.join(output_dir, 'market_returns.parquet'),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"Saved: market_returns.parquet\")\n",
    "    \n",
    "    # Fama-French factors\n",
    "    if len(ff_factors) > 0:\n",
    "        ff_factors.to_parquet(\n",
    "            os.path.join(output_dir, 'ff_factors.parquet'),\n",
    "            index=False\n",
    "        )\n",
    "        print(f\"Saved: ff_factors.parquet\")\n",
    "    \n",
    "    # Firm characteristics\n",
    "    firm_characteristics.to_parquet(\n",
    "        os.path.join(output_dir, 'firm_characteristics.parquet'),\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"Saved: firm_characteristics.parquet\")\n",
    "    \n",
    "    # Data dictionary\n",
    "    data_dict = {\n",
    "        'stock_returns_panel': {\n",
    "            'ticker': 'Stock ticker symbol',\n",
    "            'date': 'Trading date',\n",
    "            'open/high/low/close': 'OHLC prices (adjusted)',\n",
    "            'volume': 'Trading volume',\n",
    "            'ret': 'Simple daily return',\n",
    "            'ret_log': 'Log daily return',\n",
    "            'market_return': 'Market (SPY) return',\n",
    "            'ret_mktadj': 'Market-adjusted return',\n",
    "            'Mkt-RF/SMB/HML/RF': 'Fama-French factors',\n",
    "            'volatility_20d': '20-day rolling volatility (annualized)',\n",
    "            'ret_1m/3m/6m/12m': 'Cumulative returns over 1/3/6/12 months',\n",
    "            'vol_1m/3m': 'Rolling volatility (1/3 months)',\n",
    "            'illiquidity_avg': 'Amihud illiquidity (21-day avg)'\n",
    "        },\n",
    "        'firm_characteristics': {\n",
    "            'ticker': 'Stock ticker symbol',\n",
    "            'sector/industry': 'GICS sector and industry',\n",
    "            'market_cap': 'Market capitalization',\n",
    "            'price_to_book': 'Price-to-book ratio',\n",
    "            'beta': 'Market beta',\n",
    "            'short_ratio': 'Short interest ratio'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, 'financial_data_dictionary.json'), 'w') as f:\n",
    "        json.dump(data_dict, f, indent=2)\n",
    "    print(\"Saved: financial_data_dictionary.json\")\n",
    "\n",
    "# Save all data\n",
    "save_financial_data(config.PROCESSED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOTEBOOK SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║        NOTEBOOK 3: FINANCIAL DATA COLLECTION COMPLETE            ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "OUTPUT FILES:\n",
    "─────────────\n",
    "• stock_returns_panel.parquet  - Daily returns with characteristics\n",
    "• market_returns.parquet       - Market index returns\n",
    "• ff_factors.parquet           - Fama-French factor returns\n",
    "• firm_characteristics.parquet - Cross-sectional firm data\n",
    "\n",
    "KEY VARIABLES:\n",
    "──────────────\n",
    "Returns:\n",
    "  • ret, ret_log (raw returns)\n",
    "  • ret_mktadj (market-adjusted)\n",
    "  • CAR calculations available\n",
    "\n",
    "Characteristics:\n",
    "  • Size (market cap)\n",
    "  • Book-to-market\n",
    "  • Momentum (1m, 3m, 6m, 12m)\n",
    "  • Volatility\n",
    "  • Liquidity (Amihud)\n",
    "\n",
    "Factors:\n",
    "  • Mkt-RF, SMB, HML (Fama-French)\n",
    "  • Risk-free rate\n",
    "\n",
    "NEXT STEPS:\n",
    "───────────\n",
    "→ Notebook 4: Earnings Quality Measures\n",
    "  - Financial statement data from SEC EDGAR\n",
    "  - Accrual-based quality metrics\n",
    "  - Dechow-Dichev model implementation\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
