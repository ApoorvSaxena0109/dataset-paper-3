{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Earnings Quality Measures\n",
    "## Accrual-Based Quality Metrics from Financial Statements\n",
    "\n",
    "---\n",
    "\n",
    "**Research Project:** Retail Sentiment, Earnings Quality, and Stock Returns\n",
    "\n",
    "**Purpose:** Compute firm-level earnings quality measures using financial statement data from SEC EDGAR.\n",
    "\n",
    "**Methodology:**\n",
    "- Dechow & Dichev (2002) accruals quality model\n",
    "- McNichols (2002) modification\n",
    "- Modified Jones (1991) discretionary accruals\n",
    "\n",
    "**Data Sources:**\n",
    "- SEC EDGAR 10-K and 10-Q filings\n",
    "- Financial statement variables\n",
    "\n",
    "**Output:** Firm-level panel with earnings quality metrics\n",
    "\n",
    "---\n",
    "\n",
    "**References:**\n",
    "- Dechow, P., & Dichev, I. (2002). The quality of accruals and earnings. The Accounting Review, 77(s-1), 35-59.\n",
    "- McNichols, M. (2002). Discussion of the quality of accruals and earnings. The Accounting Review, 77(s-1), 61-69.\n",
    "- Jones, J. (1991). Earnings management during import relief investigations. Journal of Accounting Research, 29(2), 193-228."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# INSTALL REQUIRED PACKAGES\n",
    "# =============================================================================\n",
    "\n",
    "!pip install pandas==2.0.3\n",
    "!pip install numpy==1.24.3\n",
    "!pip install scipy==1.11.3\n",
    "!pip install statsmodels==0.14.0\n",
    "!pip install requests==2.31.0\n",
    "!pip install beautifulsoup4==4.12.2\n",
    "!pip install lxml==4.9.3\n",
    "!pip install sec-edgar-downloader==5.0.0\n",
    "!pip install tqdm==4.66.1\n",
    "!pip install pyarrow==14.0.1\n",
    "!pip install yfinance==0.2.31\n",
    "\n",
    "print(\"All packages installed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORT LIBRARIES\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import yfinance as yf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "print(f\"Environment setup complete. Timestamp: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "class EarningsQualityConfig:\n",
    "    \"\"\"Configuration for earnings quality analysis.\"\"\"\n",
    "    \n",
    "    # Data paths\n",
    "    BASE_PATH = \"/content/drive/MyDrive/Research/RetailSentiment/\"\n",
    "    RAW_DATA_PATH = BASE_PATH + \"data/raw/\"\n",
    "    PROCESSED_DATA_PATH = BASE_PATH + \"data/processed/\"\n",
    "    \n",
    "    # Sample period\n",
    "    START_YEAR = 2015  # Extra years for rolling estimation\n",
    "    END_YEAR = 2023\n",
    "    \n",
    "    # Dechow-Dichev model parameters\n",
    "    DD_ROLLING_WINDOW = 5  # Years for rolling regression\n",
    "    DD_MIN_OBSERVATIONS = 3  # Minimum years required\n",
    "    \n",
    "    # Industry classification\n",
    "    INDUSTRY_MIN_FIRMS = 10  # Minimum firms for industry regression\n",
    "    \n",
    "    # Winsorization\n",
    "    WINSORIZE_LEVEL = 0.01  # 1% and 99%\n",
    "    \n",
    "    # SEC EDGAR\n",
    "    SEC_EMAIL = \"research@university.edu\"  # Required for SEC API\n",
    "    SEC_RATE_LIMIT = 10  # Requests per second\n",
    "    \n",
    "    @classmethod\n",
    "    def print_config(cls):\n",
    "        print(\"=\"*60)\n",
    "        print(\"EARNINGS QUALITY CONFIGURATION\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Period: {cls.START_YEAR} to {cls.END_YEAR}\")\n",
    "        print(f\"DD Rolling Window: {cls.DD_ROLLING_WINDOW} years\")\n",
    "        print(f\"Industry Min Firms: {cls.INDUSTRY_MIN_FIRMS}\")\n",
    "        print(f\"Winsorization: {cls.WINSORIZE_LEVEL*100}%\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "config = EarningsQualityConfig()\n",
    "config.print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MOUNT GOOGLE DRIVE\n",
    "# =============================================================================\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "os.makedirs(config.RAW_DATA_PATH, exist_ok=True)\n",
    "os.makedirs(config.PROCESSED_DATA_PATH, exist_ok=True)\n",
    "print(\"Data directories ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Financial Statement Data Collection\n",
    "\n",
    "### 2.1 SEC EDGAR Data Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SEC EDGAR DATA COLLECTOR\n",
    "# =============================================================================\n",
    "\n",
    "class SECEdgarCollector:\n",
    "    \"\"\"Collects financial statement data from SEC EDGAR.\n",
    "    \n",
    "    Uses the SEC EDGAR API to retrieve:\n",
    "    - Balance sheet items\n",
    "    - Income statement items\n",
    "    - Cash flow statement items\n",
    "    \"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://data.sec.gov\"\n",
    "    COMPANY_FACTS_URL = BASE_URL + \"/api/xbrl/companyfacts/CIK{cik}.json\"\n",
    "    \n",
    "    # Key XBRL tags for earnings quality calculation\n",
    "    REQUIRED_TAGS = {\n",
    "        # Balance Sheet\n",
    "        'Assets': ['Assets'],\n",
    "        'CurrentAssets': ['AssetsCurrent'],\n",
    "        'Cash': ['CashAndCashEquivalentsAtCarryingValue', 'Cash'],\n",
    "        'Receivables': ['AccountsReceivableNetCurrent', 'ReceivablesNetCurrent'],\n",
    "        'Inventory': ['InventoryNet'],\n",
    "        'CurrentLiabilities': ['LiabilitiesCurrent'],\n",
    "        'AccountsPayable': ['AccountsPayableCurrent'],\n",
    "        'DebtCurrent': ['DebtCurrent', 'ShortTermBorrowings'],\n",
    "        'PPE': ['PropertyPlantAndEquipmentNet'],\n",
    "        \n",
    "        # Income Statement\n",
    "        'Revenue': ['Revenues', 'RevenueFromContractWithCustomerExcludingAssessedTax', 'SalesRevenueNet'],\n",
    "        'NetIncome': ['NetIncomeLoss', 'ProfitLoss'],\n",
    "        'DepreciationAmortization': ['DepreciationDepletionAndAmortization', 'Depreciation'],\n",
    "        \n",
    "        # Cash Flow\n",
    "        'OperatingCashFlow': ['NetCashProvidedByUsedInOperatingActivities'],\n",
    "    }\n",
    "    \n",
    "    def __init__(self, email: str):\n",
    "        \"\"\"Initialize collector with email for SEC API.\"\"\"\n",
    "        self.headers = {\n",
    "            'User-Agent': f'Academic Research ({email})',\n",
    "            'Accept-Encoding': 'gzip, deflate'\n",
    "        }\n",
    "        self.cik_mapping = {}\n",
    "        \n",
    "    def get_cik_from_ticker(self, ticker: str) -> Optional[str]:\n",
    "        \"\"\"Get CIK number from ticker symbol.\"\"\"\n",
    "        try:\n",
    "            url = f\"{self.BASE_URL}/submissions/CIK{ticker.upper()}.json\"\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            if response.status_code == 200:\n",
    "                return response.json().get('cik', '').zfill(10)\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    def load_cik_mapping(self) -> Dict[str, str]:\n",
    "        \"\"\"Load ticker to CIK mapping from SEC.\"\"\"\n",
    "        print(\"Loading CIK mapping from SEC...\")\n",
    "        url = f\"{self.BASE_URL}/files/company_tickers.json\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            data = response.json()\n",
    "            \n",
    "            for item in data.values():\n",
    "                ticker = item['ticker']\n",
    "                cik = str(item['cik_str']).zfill(10)\n",
    "                self.cik_mapping[ticker] = cik\n",
    "            \n",
    "            print(f\"Loaded {len(self.cik_mapping)} ticker-CIK mappings\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading CIK mapping: {e}\")\n",
    "        \n",
    "        return self.cik_mapping\n",
    "    \n",
    "    def get_company_facts(self, cik: str) -> Optional[Dict]:\n",
    "        \"\"\"Get all financial facts for a company.\"\"\"\n",
    "        url = self.COMPANY_FACTS_URL.format(cik=cik)\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            if response.status_code == 200:\n",
    "                return response.json()\n",
    "        except:\n",
    "            pass\n",
    "        return None\n",
    "    \n",
    "    def extract_financial_data(self, facts: Dict, ticker: str) -> pd.DataFrame:\n",
    "        \"\"\"Extract relevant financial data from company facts.\"\"\"\n",
    "        if not facts or 'facts' not in facts:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        all_data = []\n",
    "        \n",
    "        # Try both US-GAAP and IFRS\n",
    "        for taxonomy in ['us-gaap', 'ifrs-full']:\n",
    "            if taxonomy not in facts['facts']:\n",
    "                continue\n",
    "            \n",
    "            taxonomy_facts = facts['facts'][taxonomy]\n",
    "            \n",
    "            for var_name, tag_list in self.REQUIRED_TAGS.items():\n",
    "                for tag in tag_list:\n",
    "                    if tag in taxonomy_facts:\n",
    "                        tag_data = taxonomy_facts[tag]\n",
    "                        \n",
    "                        if 'units' not in tag_data:\n",
    "                            continue\n",
    "                        \n",
    "                        # Get USD values\n",
    "                        for unit_type in ['USD', 'USD/shares']:\n",
    "                            if unit_type in tag_data['units']:\n",
    "                                for entry in tag_data['units'][unit_type]:\n",
    "                                    # Only quarterly/annual filings\n",
    "                                    form = entry.get('form', '')\n",
    "                                    if form not in ['10-Q', '10-K']:\n",
    "                                        continue\n",
    "                                    \n",
    "                                    all_data.append({\n",
    "                                        'ticker': ticker,\n",
    "                                        'variable': var_name,\n",
    "                                        'value': entry.get('val'),\n",
    "                                        'end_date': entry.get('end'),\n",
    "                                        'filed_date': entry.get('filed'),\n",
    "                                        'form': form,\n",
    "                                        'fiscal_year': entry.get('fy'),\n",
    "                                        'fiscal_period': entry.get('fp'),\n",
    "                                        'frame': entry.get('frame')\n",
    "                                    })\n",
    "                        break  # Found tag, move to next variable\n",
    "        \n",
    "        return pd.DataFrame(all_data)\n",
    "    \n",
    "    def collect_financials(self, tickers: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Collect financial data for multiple tickers.\"\"\"\n",
    "        print(f\"Collecting financial data for {len(tickers)} tickers...\")\n",
    "        \n",
    "        if not self.cik_mapping:\n",
    "            self.load_cik_mapping()\n",
    "        \n",
    "        all_financials = []\n",
    "        failed_tickers = []\n",
    "        \n",
    "        for ticker in tqdm(tickers, desc=\"Fetching SEC data\"):\n",
    "            cik = self.cik_mapping.get(ticker)\n",
    "            if not cik:\n",
    "                failed_tickers.append(ticker)\n",
    "                continue\n",
    "            \n",
    "            facts = self.get_company_facts(cik)\n",
    "            if facts:\n",
    "                df = self.extract_financial_data(facts, ticker)\n",
    "                if len(df) > 0:\n",
    "                    all_financials.append(df)\n",
    "            else:\n",
    "                failed_tickers.append(ticker)\n",
    "            \n",
    "            time.sleep(0.1)  # Rate limiting\n",
    "        \n",
    "        if all_financials:\n",
    "            result = pd.concat(all_financials, ignore_index=True)\n",
    "            result['end_date'] = pd.to_datetime(result['end_date'])\n",
    "            result['filed_date'] = pd.to_datetime(result['filed_date'])\n",
    "            \n",
    "            print(f\"\\nCollection complete:\")\n",
    "            print(f\"  Tickers collected: {result['ticker'].nunique()}\")\n",
    "            print(f\"  Failed tickers: {len(failed_tickers)}\")\n",
    "            print(f\"  Total observations: {len(result):,}\")\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# Initialize collector\n",
    "sec_collector = SECEdgarCollector(config.SEC_EMAIL)\n",
    "sec_collector.load_cik_mapping()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Alternative: Yahoo Finance Financials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# YAHOO FINANCE FINANCIAL STATEMENT COLLECTOR\n",
    "# =============================================================================\n",
    "\n",
    "class YahooFinancialsCollector:\n",
    "    \"\"\"Alternative financial data collection using Yahoo Finance.\n",
    "    \n",
    "    Simpler interface but may have less historical depth.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def get_financials(self, ticker: str) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Get quarterly and annual financial statements.\n",
    "        \n",
    "        Args:\n",
    "            ticker: Stock ticker\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with financial statements\n",
    "        \"\"\"\n",
    "        try:\n",
    "            stock = yf.Ticker(ticker)\n",
    "            \n",
    "            return {\n",
    "                'quarterly_financials': stock.quarterly_financials,\n",
    "                'quarterly_balance_sheet': stock.quarterly_balance_sheet,\n",
    "                'quarterly_cashflow': stock.quarterly_cashflow,\n",
    "                'annual_financials': stock.financials,\n",
    "                'annual_balance_sheet': stock.balance_sheet,\n",
    "                'annual_cashflow': stock.cashflow\n",
    "            }\n",
    "        except:\n",
    "            return {}\n",
    "    \n",
    "    def collect_all_financials(self, tickers: List[str]) -> pd.DataFrame:\n",
    "        \"\"\"Collect financial data for multiple tickers.\"\"\"\n",
    "        print(f\"Collecting Yahoo Finance data for {len(tickers)} tickers...\")\n",
    "        \n",
    "        all_data = []\n",
    "        \n",
    "        for ticker in tqdm(tickers, desc=\"Fetching financials\"):\n",
    "            financials = self.get_financials(ticker)\n",
    "            \n",
    "            if financials:\n",
    "                # Process quarterly data\n",
    "                for key, df in financials.items():\n",
    "                    if df is not None and not df.empty:\n",
    "                        df_long = df.T.reset_index()\n",
    "                        df_long = df_long.melt(\n",
    "                            id_vars=['index'],\n",
    "                            var_name='variable',\n",
    "                            value_name='value'\n",
    "                        )\n",
    "                        df_long['ticker'] = ticker\n",
    "                        df_long['period_end'] = df_long['index']\n",
    "                        df_long['source'] = key\n",
    "                        all_data.append(df_long)\n",
    "            \n",
    "            time.sleep(0.2)\n",
    "        \n",
    "        if all_data:\n",
    "            result = pd.concat(all_data, ignore_index=True)\n",
    "            print(f\"Collected data for {result['ticker'].nunique()} tickers\")\n",
    "            return result\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "# Initialize Yahoo collector\n",
    "yahoo_fin_collector = YahooFinancialsCollector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD TICKER UNIVERSE AND COLLECT DATA\n",
    "# =============================================================================\n",
    "\n",
    "# Load tickers from previous notebooks\n",
    "def load_tickers():\n",
    "    filepath = os.path.join(config.PROCESSED_DATA_PATH, 'wsb_firm_day_panel.parquet')\n",
    "    if os.path.exists(filepath):\n",
    "        df = pd.read_parquet(filepath)\n",
    "        return df['ticker'].unique().tolist()\n",
    "    else:\n",
    "        # Fallback to S&P 500\n",
    "        tables = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "        return tables[0]['Symbol'].str.replace('.', '-').tolist()\n",
    "\n",
    "tickers = load_tickers()\n",
    "print(f\"Loaded {len(tickers)} tickers\")\n",
    "\n",
    "# Collect financial data (using Yahoo Finance for simplicity)\n",
    "# For production, use SEC EDGAR for more complete data\n",
    "financial_data = yahoo_fin_collector.collect_all_financials(tickers[:100])  # Subset for demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Accruals\n",
    "\n",
    "### 3.1 Working Capital Accruals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ACCRUALS CALCULATOR\n",
    "# =============================================================================\n",
    "\n",
    "class AccrualsCalculator:\n",
    "    \"\"\"Calculates various accruals measures from financial statements.\n",
    "    \n",
    "    Implements:\n",
    "    1. Total Accruals (balance sheet approach)\n",
    "    2. Working Capital Accruals (for Dechow-Dichev)\n",
    "    3. Cash Flow-based Accruals\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def prepare_panel_data(self, raw_data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Convert raw financial data to panel format.\n",
    "        \n",
    "        Args:\n",
    "            raw_data: Long-format financial data\n",
    "            \n",
    "        Returns:\n",
    "            Wide-format panel with one row per ticker-period\n",
    "        \"\"\"\n",
    "        print(\"Preparing panel data...\")\n",
    "        \n",
    "        # Pivot to wide format\n",
    "        # First, standardize variable names\n",
    "        var_mapping = {\n",
    "            'Total Assets': 'total_assets',\n",
    "            'Total Current Assets': 'current_assets',\n",
    "            'Cash And Cash Equivalents': 'cash',\n",
    "            'Cash Cash Equivalents And Short Term Investments': 'cash',\n",
    "            'Accounts Receivable': 'receivables',\n",
    "            'Net Receivables': 'receivables',\n",
    "            'Inventory': 'inventory',\n",
    "            'Total Current Liabilities': 'current_liabilities',\n",
    "            'Accounts Payable': 'accounts_payable',\n",
    "            'Short Long Term Debt': 'short_term_debt',\n",
    "            'Current Debt': 'short_term_debt',\n",
    "            'Property Plant Equipment Net': 'ppe_net',\n",
    "            'Net PPE': 'ppe_net',\n",
    "            'Total Revenue': 'revenue',\n",
    "            'Net Income': 'net_income',\n",
    "            'Depreciation And Amortization': 'depreciation',\n",
    "            'Depreciation': 'depreciation',\n",
    "            'Operating Cash Flow': 'operating_cf',\n",
    "            'Cash Flow From Continuing Operating Activities': 'operating_cf'\n",
    "        }\n",
    "        \n",
    "        df = raw_data.copy()\n",
    "        df['var_std'] = df['variable'].map(var_mapping)\n",
    "        df = df[df['var_std'].notna()]\n",
    "        \n",
    "        # Pivot\n",
    "        panel = df.pivot_table(\n",
    "            index=['ticker', 'period_end'],\n",
    "            columns='var_std',\n",
    "            values='value',\n",
    "            aggfunc='first'\n",
    "        ).reset_index()\n",
    "        \n",
    "        panel['period_end'] = pd.to_datetime(panel['period_end'])\n",
    "        panel = panel.sort_values(['ticker', 'period_end'])\n",
    "        \n",
    "        print(f\"Panel created: {len(panel)} observations, {panel['ticker'].nunique()} firms\")\n",
    "        return panel\n",
    "    \n",
    "    def calculate_working_capital_accruals(self, panel: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate working capital accruals.\n",
    "        \n",
    "        WC_Accruals = ΔCA - ΔCash - ΔCL + ΔDebt\n",
    "        \n",
    "        where:\n",
    "        - ΔCA = change in current assets\n",
    "        - ΔCash = change in cash\n",
    "        - ΔCL = change in current liabilities\n",
    "        - ΔDebt = change in short-term debt\n",
    "        \"\"\"\n",
    "        print(\"Calculating working capital accruals...\")\n",
    "        df = panel.sort_values(['ticker', 'period_end']).copy()\n",
    "        \n",
    "        # Lagged values\n",
    "        for col in ['current_assets', 'cash', 'current_liabilities', 'short_term_debt', 'total_assets']:\n",
    "            if col in df.columns:\n",
    "                df[f'{col}_lag'] = df.groupby('ticker')[col].shift(1)\n",
    "        \n",
    "        # Changes\n",
    "        df['delta_ca'] = df['current_assets'] - df.get('current_assets_lag', 0)\n",
    "        df['delta_cash'] = df['cash'] - df.get('cash_lag', 0)\n",
    "        df['delta_cl'] = df['current_liabilities'] - df.get('current_liabilities_lag', 0)\n",
    "        df['delta_debt'] = df.get('short_term_debt', 0) - df.get('short_term_debt_lag', 0)\n",
    "        \n",
    "        # Working capital accruals\n",
    "        df['wc_accruals'] = (\n",
    "            df['delta_ca'] - \n",
    "            df['delta_cash'] - \n",
    "            df['delta_cl'] + \n",
    "            df['delta_debt'].fillna(0)\n",
    "        )\n",
    "        \n",
    "        # Scale by average total assets\n",
    "        df['avg_assets'] = (df['total_assets'] + df.get('total_assets_lag', df['total_assets'])) / 2\n",
    "        df['wc_accruals_scaled'] = df['wc_accruals'] / df['avg_assets']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def calculate_total_accruals(self, panel: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Calculate total accruals using balance sheet approach.\n",
    "        \n",
    "        Total_Accruals = (ΔCA - ΔCash) - (ΔCL - ΔDebt - ΔTaxes) - Depreciation\n",
    "        \n",
    "        Or using cash flow approach:\n",
    "        Total_Accruals = Net Income - Operating Cash Flow\n",
    "        \"\"\"\n",
    "        print(\"Calculating total accruals...\")\n",
    "        df = panel.copy()\n",
    "        \n",
    "        # Cash flow approach (more reliable)\n",
    "        if 'net_income' in df.columns and 'operating_cf' in df.columns:\n",
    "            df['total_accruals'] = df['net_income'] - df['operating_cf']\n",
    "            df['total_accruals_scaled'] = df['total_accruals'] / df['avg_assets']\n",
    "        \n",
    "        return df\n",
    "\n",
    "# Initialize calculator\n",
    "accruals_calc = AccrualsCalculator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PREPARE DATA AND CALCULATE ACCRUALS\n",
    "# =============================================================================\n",
    "\n",
    "# Prepare panel data\n",
    "if len(financial_data) > 0:\n",
    "    panel_data = accruals_calc.prepare_panel_data(financial_data)\n",
    "    \n",
    "    # Calculate accruals\n",
    "    panel_data = accruals_calc.calculate_working_capital_accruals(panel_data)\n",
    "    panel_data = accruals_calc.calculate_total_accruals(panel_data)\n",
    "    \n",
    "    print(\"\\nAccruals Summary Statistics:\")\n",
    "    if 'wc_accruals_scaled' in panel_data.columns:\n",
    "        print(panel_data['wc_accruals_scaled'].describe())\n",
    "else:\n",
    "    print(\"No financial data available - creating synthetic data for demonstration\")\n",
    "    # Create synthetic panel for demonstration\n",
    "    np.random.seed(42)\n",
    "    n_firms = 100\n",
    "    n_periods = 20\n",
    "    \n",
    "    panel_data = pd.DataFrame({\n",
    "        'ticker': np.repeat([f'TICK{i}' for i in range(n_firms)], n_periods),\n",
    "        'period_end': np.tile(pd.date_range('2019-01-01', periods=n_periods, freq='Q'), n_firms),\n",
    "        'wc_accruals_scaled': np.random.normal(0, 0.05, n_firms * n_periods),\n",
    "        'total_accruals_scaled': np.random.normal(-0.05, 0.08, n_firms * n_periods),\n",
    "        'operating_cf': np.random.normal(0.1, 0.15, n_firms * n_periods) * 1e9,\n",
    "        'avg_assets': np.random.uniform(1e9, 50e9, n_firms * n_periods),\n",
    "        'revenue': np.random.uniform(0.5e9, 20e9, n_firms * n_periods),\n",
    "        'ppe_net': np.random.uniform(0.2e9, 10e9, n_firms * n_periods)\n",
    "    })\n",
    "    \n",
    "    # Add lagged/lead cash flows for DD model\n",
    "    panel_data = panel_data.sort_values(['ticker', 'period_end'])\n",
    "    panel_data['cfo_scaled'] = panel_data['operating_cf'] / panel_data['avg_assets']\n",
    "    panel_data['cfo_lag'] = panel_data.groupby('ticker')['cfo_scaled'].shift(1)\n",
    "    panel_data['cfo_lead'] = panel_data.groupby('ticker')['cfo_scaled'].shift(-1)\n",
    "    \n",
    "    # Add industry\n",
    "    industries = ['Technology', 'Healthcare', 'Finance', 'Consumer', 'Industrial']\n",
    "    panel_data['industry'] = np.tile(\n",
    "        np.repeat(industries, n_firms // len(industries) + 1)[:n_firms],\n",
    "        n_periods\n",
    "    )\n",
    "    \n",
    "    print(f\"Created synthetic panel: {len(panel_data)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dechow-Dichev Earnings Quality Model\n",
    "\n",
    "### 4.1 Model Specification\n",
    "\n",
    "The Dechow-Dichev (2002) model measures earnings quality as the mapping of accruals into cash flows:\n",
    "\n",
    "$$\\Delta WC_t = \\beta_0 + \\beta_1 CFO_{t-1} + \\beta_2 CFO_t + \\beta_3 CFO_{t+1} + \\epsilon_t$$\n",
    "\n",
    "Earnings quality = σ(residuals) over rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DECHOW-DICHEV EARNINGS QUALITY MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class DechowDichevModel:\n",
    "    \"\"\"Implements the Dechow-Dichev (2002) accruals quality model.\n",
    "    \n",
    "    Model: WC_Accruals_t = a + b1*CFO_{t-1} + b2*CFO_t + b3*CFO_{t+1} + e_t\n",
    "    \n",
    "    Earnings Quality = σ(residuals) over rolling window\n",
    "    Higher residual std = Lower earnings quality\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: EarningsQualityConfig):\n",
    "        self.config = config\n",
    "        self.model_results = {}\n",
    "        \n",
    "    def prepare_variables(self, panel: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Prepare variables for DD model.\n",
    "        \n",
    "        Args:\n",
    "            panel: Panel data with accruals and cash flows\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with DD model variables\n",
    "        \"\"\"\n",
    "        df = panel.sort_values(['ticker', 'period_end']).copy()\n",
    "        \n",
    "        # Ensure CFO variables exist\n",
    "        if 'cfo_scaled' not in df.columns:\n",
    "            df['cfo_scaled'] = df['operating_cf'] / df['avg_assets']\n",
    "        \n",
    "        # Create lags and leads\n",
    "        if 'cfo_lag' not in df.columns:\n",
    "            df['cfo_lag'] = df.groupby('ticker')['cfo_scaled'].shift(1)\n",
    "        if 'cfo_lead' not in df.columns:\n",
    "            df['cfo_lead'] = df.groupby('ticker')['cfo_scaled'].shift(-1)\n",
    "        \n",
    "        # Winsorize\n",
    "        for col in ['wc_accruals_scaled', 'cfo_scaled', 'cfo_lag', 'cfo_lead']:\n",
    "            if col in df.columns:\n",
    "                df[col] = self._winsorize(df[col], self.config.WINSORIZE_LEVEL)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def _winsorize(self, series: pd.Series, level: float) -> pd.Series:\n",
    "        \"\"\"Winsorize series at specified level.\"\"\"\n",
    "        lower = series.quantile(level)\n",
    "        upper = series.quantile(1 - level)\n",
    "        return series.clip(lower=lower, upper=upper)\n",
    "    \n",
    "    def estimate_firm_level(self, panel: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Estimate DD model at firm level using time series.\n",
    "        \n",
    "        For each firm, run rolling regressions and compute residual std.\n",
    "        \n",
    "        Args:\n",
    "            panel: Prepared panel data\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with firm-level earnings quality\n",
    "        \"\"\"\n",
    "        print(\"Estimating firm-level Dechow-Dichev model...\")\n",
    "        df = self.prepare_variables(panel)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for ticker in tqdm(df['ticker'].unique(), desc=\"Estimating DD model\"):\n",
    "            firm_data = df[df['ticker'] == ticker].sort_values('period_end')\n",
    "            \n",
    "            # Need sufficient observations\n",
    "            valid_data = firm_data.dropna(\n",
    "                subset=['wc_accruals_scaled', 'cfo_scaled', 'cfo_lag', 'cfo_lead']\n",
    "            )\n",
    "            \n",
    "            if len(valid_data) < self.config.DD_MIN_OBSERVATIONS * 4:\n",
    "                continue\n",
    "            \n",
    "            # Prepare regression variables\n",
    "            y = valid_data['wc_accruals_scaled']\n",
    "            X = sm.add_constant(valid_data[['cfo_lag', 'cfo_scaled', 'cfo_lead']])\n",
    "            \n",
    "            try:\n",
    "                # Estimate model\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                \n",
    "                # Get residuals\n",
    "                residuals = model.resid\n",
    "                \n",
    "                # Rolling std of residuals (earnings quality measure)\n",
    "                window = self.config.DD_ROLLING_WINDOW * 4  # Quarterly\n",
    "                if len(residuals) >= window:\n",
    "                    rolling_std = residuals.rolling(window=window, min_periods=window//2).std()\n",
    "                else:\n",
    "                    rolling_std = pd.Series([residuals.std()] * len(residuals), index=residuals.index)\n",
    "                \n",
    "                # Store results for each period\n",
    "                for idx, (period, resid_std) in enumerate(zip(\n",
    "                    valid_data['period_end'], rolling_std\n",
    "                )):\n",
    "                    results.append({\n",
    "                        'ticker': ticker,\n",
    "                        'period_end': period,\n",
    "                        'dd_residual': residuals.iloc[idx] if idx < len(residuals) else np.nan,\n",
    "                        'dd_residual_std': resid_std,\n",
    "                        'dd_r_squared': model.rsquared,\n",
    "                        'dd_n_obs': len(valid_data)\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Higher residual std = lower quality, so invert for intuitive interpretation\n",
    "        result_df['earnings_quality_dd'] = -result_df['dd_residual_std']\n",
    "        \n",
    "        # Standardize\n",
    "        mean_eq = result_df['earnings_quality_dd'].mean()\n",
    "        std_eq = result_df['earnings_quality_dd'].std()\n",
    "        result_df['earnings_quality_dd_std'] = (\n",
    "            (result_df['earnings_quality_dd'] - mean_eq) / std_eq\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nDD Model Results:\")\n",
    "        print(f\"  Firms: {result_df['ticker'].nunique()}\")\n",
    "        print(f\"  Observations: {len(result_df)}\")\n",
    "        print(f\"  Avg R-squared: {result_df['dd_r_squared'].mean():.3f}\")\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def estimate_cross_sectional(self, panel: pd.DataFrame,\n",
    "                                 group_col: str = 'industry') -> pd.DataFrame:\n",
    "        \"\"\"Estimate DD model cross-sectionally by industry-period.\n",
    "        \n",
    "        Alternative approach that estimates within industry-quarter groups.\n",
    "        \n",
    "        Args:\n",
    "            panel: Prepared panel data\n",
    "            group_col: Column for grouping (e.g., 'industry')\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with earnings quality based on cross-sectional residuals\n",
    "        \"\"\"\n",
    "        print(f\"Estimating cross-sectional DD model by {group_col}...\")\n",
    "        df = self.prepare_variables(panel)\n",
    "        \n",
    "        # Add period identifier\n",
    "        df['year_quarter'] = df['period_end'].dt.to_period('Q')\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # Group by industry-quarter\n",
    "        for (group, period), group_data in tqdm(\n",
    "            df.groupby([group_col, 'year_quarter']),\n",
    "            desc=\"Processing groups\"\n",
    "        ):\n",
    "            valid_data = group_data.dropna(\n",
    "                subset=['wc_accruals_scaled', 'cfo_scaled', 'cfo_lag', 'cfo_lead']\n",
    "            )\n",
    "            \n",
    "            if len(valid_data) < self.config.INDUSTRY_MIN_FIRMS:\n",
    "                continue\n",
    "            \n",
    "            y = valid_data['wc_accruals_scaled']\n",
    "            X = sm.add_constant(valid_data[['cfo_lag', 'cfo_scaled', 'cfo_lead']])\n",
    "            \n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                \n",
    "                for ticker, resid in zip(valid_data['ticker'], model.resid):\n",
    "                    results.append({\n",
    "                        'ticker': ticker,\n",
    "                        'period_end': valid_data[valid_data['ticker'] == ticker]['period_end'].iloc[0],\n",
    "                        group_col: group,\n",
    "                        'year_quarter': period,\n",
    "                        'dd_residual_cs': resid,\n",
    "                        'dd_r_squared_cs': model.rsquared\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Calculate firm-level quality as std of residuals over time\n",
    "        firm_quality = result_df.groupby('ticker').agg({\n",
    "            'dd_residual_cs': 'std'\n",
    "        }).reset_index()\n",
    "        firm_quality.columns = ['ticker', 'eq_dd_cs_std']\n",
    "        \n",
    "        result_df = result_df.merge(firm_quality, on='ticker', how='left')\n",
    "        result_df['earnings_quality_dd_cs'] = -result_df['eq_dd_cs_std']\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "# Initialize DD model\n",
    "dd_model = DechowDichevModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# ESTIMATE DECHOW-DICHEV MODEL\n",
    "# =============================================================================\n",
    "\n",
    "# Estimate firm-level DD model\n",
    "dd_results = dd_model.estimate_firm_level(panel_data)\n",
    "\n",
    "print(\"\\nEarnings Quality (DD) Distribution:\")\n",
    "print(dd_results['earnings_quality_dd_std'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. McNichols Modification\n",
    "\n",
    "### 5.1 Extended Model with Growth and PPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# McNICHOLS EXTENDED MODEL\n",
    "# =============================================================================\n",
    "\n",
    "class McNicholsModel:\n",
    "    \"\"\"Implements the McNichols (2002) modification of DD model.\n",
    "    \n",
    "    Extends DD model with:\n",
    "    - Change in revenue (growth)\n",
    "    - PPE (property, plant, equipment)\n",
    "    \n",
    "    Model: WC_Accruals_t = a + b1*CFO_{t-1} + b2*CFO_t + b3*CFO_{t+1} \n",
    "                          + b4*ΔRev_t + b5*PPE_t + e_t\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: EarningsQualityConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def prepare_variables(self, panel: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Prepare additional variables for McNichols model.\"\"\"\n",
    "        df = panel.sort_values(['ticker', 'period_end']).copy()\n",
    "        \n",
    "        # Revenue change\n",
    "        df['revenue_lag'] = df.groupby('ticker')['revenue'].shift(1)\n",
    "        df['delta_revenue'] = df['revenue'] - df['revenue_lag']\n",
    "        df['delta_revenue_scaled'] = df['delta_revenue'] / df['avg_assets']\n",
    "        \n",
    "        # PPE scaled\n",
    "        df['ppe_scaled'] = df['ppe_net'] / df['avg_assets']\n",
    "        \n",
    "        # Winsorize\n",
    "        for col in ['delta_revenue_scaled', 'ppe_scaled']:\n",
    "            if col in df.columns:\n",
    "                lower = df[col].quantile(self.config.WINSORIZE_LEVEL)\n",
    "                upper = df[col].quantile(1 - self.config.WINSORIZE_LEVEL)\n",
    "                df[col] = df[col].clip(lower=lower, upper=upper)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def estimate(self, panel: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Estimate McNichols model.\n",
    "        \n",
    "        Args:\n",
    "            panel: Panel data with accruals and financial variables\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with McNichols earnings quality\n",
    "        \"\"\"\n",
    "        print(\"Estimating McNichols model...\")\n",
    "        df = self.prepare_variables(panel)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for ticker in tqdm(df['ticker'].unique(), desc=\"Estimating McNichols\"):\n",
    "            firm_data = df[df['ticker'] == ticker].sort_values('period_end')\n",
    "            \n",
    "            valid_data = firm_data.dropna(subset=[\n",
    "                'wc_accruals_scaled', 'cfo_scaled', 'cfo_lag', 'cfo_lead',\n",
    "                'delta_revenue_scaled', 'ppe_scaled'\n",
    "            ])\n",
    "            \n",
    "            if len(valid_data) < self.config.DD_MIN_OBSERVATIONS * 4:\n",
    "                continue\n",
    "            \n",
    "            y = valid_data['wc_accruals_scaled']\n",
    "            X = sm.add_constant(valid_data[[\n",
    "                'cfo_lag', 'cfo_scaled', 'cfo_lead',\n",
    "                'delta_revenue_scaled', 'ppe_scaled'\n",
    "            ]])\n",
    "            \n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                residuals = model.resid\n",
    "                \n",
    "                # Rolling std\n",
    "                window = self.config.DD_ROLLING_WINDOW * 4\n",
    "                if len(residuals) >= window:\n",
    "                    rolling_std = residuals.rolling(window=window, min_periods=window//2).std()\n",
    "                else:\n",
    "                    rolling_std = pd.Series([residuals.std()] * len(residuals), index=residuals.index)\n",
    "                \n",
    "                for idx, (period, resid_std) in enumerate(zip(\n",
    "                    valid_data['period_end'], rolling_std\n",
    "                )):\n",
    "                    results.append({\n",
    "                        'ticker': ticker,\n",
    "                        'period_end': period,\n",
    "                        'mcnichols_residual': residuals.iloc[idx] if idx < len(residuals) else np.nan,\n",
    "                        'mcnichols_residual_std': resid_std,\n",
    "                        'mcnichols_r_squared': model.rsquared\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        result_df = pd.DataFrame(results)\n",
    "        result_df['earnings_quality_mcn'] = -result_df['mcnichols_residual_std']\n",
    "        \n",
    "        # Standardize\n",
    "        result_df['earnings_quality_mcn_std'] = (\n",
    "            (result_df['earnings_quality_mcn'] - result_df['earnings_quality_mcn'].mean()) /\n",
    "            result_df['earnings_quality_mcn'].std()\n",
    "        )\n",
    "        \n",
    "        print(f\"McNichols Model Complete:\")\n",
    "        print(f\"  Firms: {result_df['ticker'].nunique()}\")\n",
    "        print(f\"  Avg R-squared: {result_df['mcnichols_r_squared'].mean():.3f}\")\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "# Initialize and estimate\n",
    "mcn_model = McNicholsModel(config)\n",
    "mcn_results = mcn_model.estimate(panel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modified Jones Model\n",
    "\n",
    "### 6.1 Discretionary Accruals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# MODIFIED JONES MODEL FOR DISCRETIONARY ACCRUALS\n",
    "# =============================================================================\n",
    "\n",
    "class ModifiedJonesModel:\n",
    "    \"\"\"Implements the Modified Jones (1991) model.\n",
    "    \n",
    "    Model: TA_t/A_{t-1} = a*(1/A_{t-1}) + b*(ΔRev_t - ΔRec_t)/A_{t-1} + c*(PPE_t/A_{t-1}) + e_t\n",
    "    \n",
    "    Discretionary Accruals = Residuals\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: EarningsQualityConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def prepare_variables(self, panel: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Prepare variables for Modified Jones model.\"\"\"\n",
    "        df = panel.sort_values(['ticker', 'period_end']).copy()\n",
    "        \n",
    "        # Lagged assets\n",
    "        df['assets_lag'] = df.groupby('ticker')['total_assets'].shift(1) if 'total_assets' in df.columns else df['avg_assets']\n",
    "        \n",
    "        # Inverse of lagged assets\n",
    "        df['inv_assets'] = 1 / df['assets_lag']\n",
    "        \n",
    "        # Change in revenue minus change in receivables (scaled)\n",
    "        if 'receivables' in df.columns:\n",
    "            df['receivables_lag'] = df.groupby('ticker')['receivables'].shift(1)\n",
    "            df['delta_rec'] = df['receivables'] - df['receivables_lag']\n",
    "        else:\n",
    "            df['delta_rec'] = 0\n",
    "        \n",
    "        df['delta_rev_adj'] = (df.get('delta_revenue', 0) - df['delta_rec']) / df['assets_lag']\n",
    "        \n",
    "        # PPE scaled\n",
    "        df['ppe_jones'] = df['ppe_net'] / df['assets_lag'] if 'ppe_net' in df.columns else 0\n",
    "        \n",
    "        # Total accruals scaled\n",
    "        if 'total_accruals' in df.columns:\n",
    "            df['ta_scaled'] = df['total_accruals'] / df['assets_lag']\n",
    "        else:\n",
    "            df['ta_scaled'] = df['wc_accruals_scaled']\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def estimate_by_industry(self, panel: pd.DataFrame,\n",
    "                            industry_col: str = 'industry') -> pd.DataFrame:\n",
    "        \"\"\"Estimate Modified Jones model by industry-year.\n",
    "        \n",
    "        Args:\n",
    "            panel: Prepared panel data\n",
    "            industry_col: Column with industry classification\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with discretionary accruals\n",
    "        \"\"\"\n",
    "        print(\"Estimating Modified Jones model by industry...\")\n",
    "        df = self.prepare_variables(panel)\n",
    "        df['year'] = df['period_end'].dt.year\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for (industry, year), group_data in tqdm(\n",
    "            df.groupby([industry_col, 'year']),\n",
    "            desc=\"Processing industry-years\"\n",
    "        ):\n",
    "            valid_data = group_data.dropna(subset=['ta_scaled', 'inv_assets', 'delta_rev_adj', 'ppe_jones'])\n",
    "            \n",
    "            if len(valid_data) < self.config.INDUSTRY_MIN_FIRMS:\n",
    "                continue\n",
    "            \n",
    "            y = valid_data['ta_scaled']\n",
    "            X = valid_data[['inv_assets', 'delta_rev_adj', 'ppe_jones']]\n",
    "            \n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                \n",
    "                for ticker, resid, fitted in zip(\n",
    "                    valid_data['ticker'], model.resid, model.fittedvalues\n",
    "                ):\n",
    "                    results.append({\n",
    "                        'ticker': ticker,\n",
    "                        'period_end': valid_data[valid_data['ticker'] == ticker]['period_end'].iloc[0],\n",
    "                        industry_col: industry,\n",
    "                        'year': year,\n",
    "                        'discretionary_accruals': resid,\n",
    "                        'nondiscretionary_accruals': fitted,\n",
    "                        'jones_r_squared': model.rsquared\n",
    "                    })\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        # Absolute discretionary accruals (common measure)\n",
    "        result_df['abs_discretionary_accruals'] = np.abs(result_df['discretionary_accruals'])\n",
    "        \n",
    "        # Quality measure (lower abs DA = higher quality)\n",
    "        result_df['earnings_quality_jones'] = -result_df['abs_discretionary_accruals']\n",
    "        \n",
    "        print(f\"Modified Jones Model Complete:\")\n",
    "        print(f\"  Firms: {result_df['ticker'].nunique()}\")\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "# Initialize and estimate\n",
    "jones_model = ModifiedJonesModel(config)\n",
    "\n",
    "# Only run if industry data available\n",
    "if 'industry' in panel_data.columns:\n",
    "    jones_results = jones_model.estimate_by_industry(panel_data)\n",
    "else:\n",
    "    print(\"Industry column not available - skipping Jones model\")\n",
    "    jones_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combine Earnings Quality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMBINE ALL EARNINGS QUALITY MEASURES\n",
    "# =============================================================================\n",
    "\n",
    "def combine_earnings_quality(\n",
    "    dd_results: pd.DataFrame,\n",
    "    mcn_results: pd.DataFrame,\n",
    "    jones_results: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Combine all earnings quality measures into one panel.\n",
    "    \n",
    "    Args:\n",
    "        dd_results: Dechow-Dichev results\n",
    "        mcn_results: McNichols results\n",
    "        jones_results: Modified Jones results\n",
    "        \n",
    "    Returns:\n",
    "        Combined earnings quality panel\n",
    "    \"\"\"\n",
    "    print(\"Combining earnings quality measures...\")\n",
    "    \n",
    "    # Start with DD results\n",
    "    combined = dd_results[['ticker', 'period_end', \n",
    "                          'dd_residual_std', 'earnings_quality_dd', \n",
    "                          'earnings_quality_dd_std', 'dd_r_squared']].copy()\n",
    "    \n",
    "    # Merge McNichols\n",
    "    if len(mcn_results) > 0:\n",
    "        combined = combined.merge(\n",
    "            mcn_results[['ticker', 'period_end', \n",
    "                        'mcnichols_residual_std', 'earnings_quality_mcn', \n",
    "                        'earnings_quality_mcn_std', 'mcnichols_r_squared']],\n",
    "            on=['ticker', 'period_end'],\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    # Merge Jones\n",
    "    if len(jones_results) > 0:\n",
    "        combined = combined.merge(\n",
    "            jones_results[['ticker', 'period_end',\n",
    "                          'discretionary_accruals', 'abs_discretionary_accruals',\n",
    "                          'earnings_quality_jones']],\n",
    "            on=['ticker', 'period_end'],\n",
    "            how='left'\n",
    "        )\n",
    "    \n",
    "    # Create composite measure (average of standardized measures)\n",
    "    eq_cols = [col for col in combined.columns if col.startswith('earnings_quality_') and '_std' in col]\n",
    "    if eq_cols:\n",
    "        combined['earnings_quality_composite'] = combined[eq_cols].mean(axis=1)\n",
    "    else:\n",
    "        combined['earnings_quality_composite'] = combined['earnings_quality_dd_std']\n",
    "    \n",
    "    # Add year/quarter\n",
    "    combined['year'] = combined['period_end'].dt.year\n",
    "    combined['quarter'] = combined['period_end'].dt.quarter\n",
    "    \n",
    "    print(f\"\\nCombined Panel:\")\n",
    "    print(f\"  Observations: {len(combined):,}\")\n",
    "    print(f\"  Firms: {combined['ticker'].nunique()}\")\n",
    "    print(f\"  Measures: {eq_cols}\")\n",
    "    \n",
    "    return combined\n",
    "\n",
    "# Combine results\n",
    "earnings_quality_panel = combine_earnings_quality(\n",
    "    dd_results,\n",
    "    mcn_results,\n",
    "    jones_results if len(jones_results) > 0 else pd.DataFrame()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EARNINGS QUALITY SUMMARY STATISTICS\n",
    "# =============================================================================\n",
    "\n",
    "def print_eq_summary(eq_panel: pd.DataFrame):\n",
    "    \"\"\"Print summary statistics for earnings quality measures.\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EARNINGS QUALITY SUMMARY STATISTICS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    eq_cols = [col for col in eq_panel.columns if 'earnings_quality' in col]\n",
    "    \n",
    "    for col in eq_cols:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(eq_panel[col].describe().to_string())\n",
    "    \n",
    "    # Correlations\n",
    "    if len(eq_cols) > 1:\n",
    "        print(\"\\nCorrelations between EQ measures:\")\n",
    "        print(eq_panel[eq_cols].corr().to_string())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "print_eq_summary(earnings_quality_panel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAVE EARNINGS QUALITY DATA\n",
    "# =============================================================================\n",
    "\n",
    "def save_earnings_quality(eq_panel: pd.DataFrame, output_dir: str):\n",
    "    \"\"\"Save earnings quality data with documentation.\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Main dataset\n",
    "    filepath = os.path.join(output_dir, 'earnings_quality_panel.parquet')\n",
    "    eq_panel.to_parquet(filepath, index=False)\n",
    "    print(f\"Saved: {filepath}\")\n",
    "    \n",
    "    # CSV sample\n",
    "    csv_path = os.path.join(output_dir, 'earnings_quality_sample.csv')\n",
    "    eq_panel.head(5000).to_csv(csv_path, index=False)\n",
    "    print(f\"Saved: {csv_path}\")\n",
    "    \n",
    "    # Data dictionary\n",
    "    data_dict = {\n",
    "        'ticker': 'Stock ticker symbol',\n",
    "        'period_end': 'Fiscal period end date',\n",
    "        'year': 'Fiscal year',\n",
    "        'quarter': 'Fiscal quarter',\n",
    "        'dd_residual_std': 'Dechow-Dichev residual standard deviation (raw)',\n",
    "        'earnings_quality_dd': 'DD earnings quality (inverted: higher = better)',\n",
    "        'earnings_quality_dd_std': 'DD earnings quality (standardized)',\n",
    "        'dd_r_squared': 'R-squared from DD model',\n",
    "        'mcnichols_residual_std': 'McNichols residual standard deviation',\n",
    "        'earnings_quality_mcn': 'McNichols earnings quality',\n",
    "        'earnings_quality_mcn_std': 'McNichols earnings quality (standardized)',\n",
    "        'discretionary_accruals': 'Modified Jones discretionary accruals',\n",
    "        'abs_discretionary_accruals': 'Absolute discretionary accruals',\n",
    "        'earnings_quality_jones': 'Jones model earnings quality',\n",
    "        'earnings_quality_composite': 'Composite EQ (average of standardized measures)'\n",
    "    }\n",
    "    \n",
    "    dict_path = os.path.join(output_dir, 'earnings_quality_dictionary.json')\n",
    "    with open(dict_path, 'w') as f:\n",
    "        json.dump(data_dict, f, indent=2)\n",
    "    print(f\"Saved: {dict_path}\")\n",
    "    \n",
    "    # Summary\n",
    "    summary = {\n",
    "        'total_observations': len(eq_panel),\n",
    "        'unique_firms': int(eq_panel['ticker'].nunique()),\n",
    "        'date_range': [str(eq_panel['period_end'].min()), str(eq_panel['period_end'].max())],\n",
    "        'measures': list(data_dict.keys()),\n",
    "        'created_at': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    summary_path = os.path.join(output_dir, 'earnings_quality_summary.json')\n",
    "    with open(summary_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(f\"Saved: {summary_path}\")\n",
    "\n",
    "# Save outputs\n",
    "save_earnings_quality(earnings_quality_panel, config.PROCESSED_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NOTEBOOK SUMMARY\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║       NOTEBOOK 4: EARNINGS QUALITY MEASURES COMPLETE             ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\n",
    "OUTPUT FILES:\n",
    "─────────────\n",
    "• earnings_quality_panel.parquet   - Firm-period earnings quality data\n",
    "• earnings_quality_dictionary.json - Variable definitions\n",
    "• earnings_quality_summary.json    - Summary statistics\n",
    "\n",
    "EARNINGS QUALITY MEASURES:\n",
    "─────────────────────────\n",
    "1. Dechow-Dichev (2002):\n",
    "   • Mapping of accruals to cash flows\n",
    "   • σ(residuals) from WC_Accruals ~ CFO_{t-1}, CFO_t, CFO_{t+1}\n",
    "\n",
    "2. McNichols (2002) Modification:\n",
    "   • Adds revenue growth and PPE\n",
    "   • Better controls for growth and capital intensity\n",
    "\n",
    "3. Modified Jones (1991):\n",
    "   • Discretionary accruals\n",
    "   • Estimated by industry-year\n",
    "\n",
    "4. Composite Measure:\n",
    "   • Average of standardized measures\n",
    "   • Higher values = Better earnings quality\n",
    "\n",
    "INTERPRETATION:\n",
    "───────────────\n",
    "• All measures scaled so HIGHER = BETTER quality\n",
    "• Standardized versions have mean=0, std=1\n",
    "• Composite provides robust overall measure\n",
    "\n",
    "NEXT STEPS:\n",
    "───────────\n",
    "→ Notebook 5: Data Merging & Final Dataset Construction\n",
    "  - Merge social media, financial, and EQ data\n",
    "  - Create event-level analysis dataset\n",
    "  - Add control variables\n",
    "\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
